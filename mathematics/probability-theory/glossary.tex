\longnewglossaryentry{event}{name=event}
{%
  Based on a \gls{event space} of possible outcomes \glssymbol{event space} and a set of measurable events \glssymbol{measurable set} to which we want to assign probabilities, an event $a \in \glssymbol{measurable set}$ is a subset of \glssymbol{event space}.\\
}

\longnewglossaryentry{event space}{name=event space,symbol={\ensuremath{\Omega}}}
{%
  A set of possible outcomes $\Omega$ with the following properties:
  \begin{itemize}
    \item It contains the empty event $\emptyset$, and the trivial event $\Omega$.
    \item It is closed under union: If $\alpha, \beta \in S$, then so is $\alpha \cup \beta$.
    \item It is closed under complementation: If $\alpha \in S$, then so is $\Omega - \alpha$.
  \end{itemize}
}

\longnewglossaryentry{measurable set}{name=measurable set,symbol=\ensuremath{\mathcal{S}}}
{%
  A set $\mathcal{S}$ is measurable if it possible to assign a number to each suitable subset of $\mathcal{S}$.
}

\longnewglossaryentry{probability distribution}{name=probability distribution}
{%
  A probability distribution $P$ over $(\glssymbol{event space},\glssymbol{measurable set})$ is a mapping from events in \glssymbol{measurable set} to real values that satisfies the following conditions:
  \begin{itemize}
    \item $P(\alpha)\geq 0 $ for all $ \alpha \in S$.
    \item $P(\glssymbol{event space})=1$.
    \item If $\alpha,\beta\in \glssymbol{event space}$ and $\alpha\cap\beta = \emptyset$, then $P(\alpha\cup\beta)=P(\alpha)+P(\beta)$.
  \end{itemize}
  Interesting conditions that are implied from these:
  \begin{itemize}
    \item $P(\emptyset)=0$
    \item $P(\alpha\cup\beta)=P(\alpha)+P(\beta)-P(\alpha\cap\beta)$
  \end{itemize}
}

\longnewglossaryentry{conditional probability}{name=conditional probability}
{%
  The conditional probability of $\beta$ given $\alpha$ is defined as (not defined for $P(\alpha)=0)$):
  \begin{equation*}
    P(\beta|\alpha)=\frac{P(\alpha\cap\beta)}{P(\alpha)}
  \end{equation*}
  $P(\beta|\alpha)$ is a \gls{probability distribution} since it satisfies its properties.
}

\longnewglossaryentry{conditional distribution}{name=conditional distribution}
{%
  A \gls{probability distribution} in the form of $P(\bm{X}|\bm{Y})$ where for each value of $\bm{Y}$ this object assigns a probability over values of $\bm{X}$ using the \gls{conditional probability}. $\bm{Y}$ represents \textit{prior} knowledge.
}


\longnewglossaryentry{chain rule}{name=chain rule}
{%
  Based on the definition of \gls{conditional probability}:
  \begin{equation*}
    P(\alpha\cap\beta)=P(\alpha)P(\beta|\alpha)
  \end{equation*}
  In general:
  \begin{equation*}
    _P(\alpha_1\cap\cdots\cap\alpha_k)=P(\alpha_1)P(\alpha_2|\alpha_1)\cdots P(\alpha_k|\alpha_1\cap\cdots\cap\alpha_{k-1})
  \end{equation*}\\[0.1cm]
  For \glspl{random variable} $\bm{X}$,$\bm{Y}$:
  \begin{equation*}
    P(\bm{X},\bm{Y})=P(\bm{X})P(\bm{Y}|\bm{X})
  \end{equation*}
  In general:
  \begin{equation*}
    P(\bm{X}_1,\dots\bm{X}_k)=P(\bm{X}_1)P(\bm{X}_2|\bm{X}_1)\cdots P(\bm{X}_k|\bm{X}_1,\cdots,\bm{X}_{k-1})
  \end{equation*}

}

\longnewglossaryentry{bayes rule}{name=Bayes' rule}
{%
  Derived from the definition of \gls{conditional probability}:
  \begin{equation*}
    P(\alpha|\beta)=\frac{P(\alpha)P(\beta|\alpha)}{P(\beta)}
  \end{equation*}\\[0.1cm]

  For \glspl{random variable} $\bm{X}$,$\bm{Y}$:
  \begin{equation*}
    P(\bm{X}|\bm{Y})=\frac{P(\bm{X})P(\bm{Y}|\bm{X})}{P(\bm{Y})}
  \end{equation*}
}

\longnewglossaryentry{random variable}{name=random variable}
{%
  A function that associates with each outcome in \glssymbol{event space} a value.

  Example: $f_{Grade}$ associates with every person in \glssymbol{event space} a grade (A,B,C). The event $Grade=A$ is short for the event $\{w\in\Omega:f_{Grade}(w)=A\}$. We can then use expressions like $P(Grade=A)$.\\

  Notation:
  \begin{itemize}
    \item $\bm{X}$,$\bm{Y}$,$\bm{Z}$... for random variables
    \item $\bm{x}$,$\bm{y}$,$\bm{z}$... for assigments of values to  $\bm{X}$,$\bm{Y}$,$\bm{Z}$: $P(\bm{X}=\bm{x})\geq0 $ for all $\bm{x}\in \gls{val}$
    \item $P(\bm{x})$ is short for $P(\bm{X}=\bm{x})$
    \item $\sum_{\bm{x}}$ is a sum over all possble values that $\bm{X}$ can take: $\sum_{\bm{x}}P(\bm{x})=1$
    \item $\bm{x}^1$,$\bm{x}^2$,...$\bm{x}^k$ for $k=|\gls{val}|$ to enumerate specific values of $\bm{X}$ with categorical values
    \item For $\bm{Y}\subseteq\bm{X}$, $\bm{x}\langle\bm{Y}\rangle$ is the assignment within $\bm{x}$ to the variables in $\bm{Y}$.
    \item For two assignments $\bm{x}$ and $\bm{y}$, $\bm{x}\sim\bm{y}$ if they agree on the variables in their intersection: $\bm{x}\langle\bm{X}\cap\bm{Y}\rangle=\bm{y}\langle\bm{X}\cap\bm{Y}\rangle$
  \end{itemize}
}

\longnewglossaryentry{val}{name=\ensuremath{Val(\bm{X})},sort=Val}
{%
  The set of values that a \gls{random variable} $\bm{X}$ can take.
}

\longnewglossaryentry{multinomial distribution}{name=multinomial distribution}
{%
  A distribution over $\bm{x}^1,\cdots,\bm{x}^k$, for $|\gls{val}|$ with $\sum_{i=1}^k P(\bm{x}^i)=1$.
}

\longnewglossaryentry{bernoulli distribution}{name=Bernoulli distribution}
{%
  A \gls{multinomial distribution} with $\gls{val}=\{false,true\}$. Typically, $\bm{x}^0$ denotes the value false and $\bm{x}^1$ the value true.
}

\longnewglossaryentry{marginal distribution}{name=marginal distribution}
{%
  A \gls{probability distribution} over events that can be described using $\bm{X}$, denoted by $P(\bm{X})$. The only difference to the definition of a \gls{probability distribution} is that here we are restricted to the subsets of \glssymbol{measurable set} that can be described with $\bm{X}$.
}

\longnewglossaryentry{joint distribution}{name=joint distribution}
{%
  A \gls{probability distribution} over a set $\mathcal{X}=\{\bm{X}_1,\cdots,\bm{X}_n\}$ denoted with $P(\bm{X}_1,\cdots,\bm{X}_n)$. It assigns probabilities to events that are specified in terms of the \glspl{random variable}. $\xi$ refers to a full assignment to the variables in $\mathcal{X}$: $\xi\in\glslink{val}{Val(\mathcal{X})}$

  Properties:
  \begin{itemize}
    \item The joint distribution of 2 variables has to be consistent with the \gls{marginal distribution}: $P(\bm{x})=\sum_{\bm{y}}P(\bm{x},\bm{y})$
    \item The most fine-grained event possible is $\bm{X}_1=\bm{x}_1$ and $\bm{X}_1=\bm{x}_1$,$\cdots$, and $\bm{X}_n=\bm{x}_n$ for a choice of values $\bm{x}_1,\cdots,\bm{x}_n$.
    \begin{itemize}
      \item Two of this events are either identical or disjoint.
      \item Any event defined using variables in $\mathcal{X}$ must be a union of a set of such events.
    \end{itemize}
    \item The probability computations remain the same whether we consider the original outcome space or the \gls{canonical outcome space}.
  \end{itemize}

}

\longnewglossaryentry{canonical outcome space}{name=canonical outcome space}
{%
  An \gls{event space} where each outcome corresponds to a \glslink{joint distribution}{joint assignment} to $\bm{X}_1,\dots, \bm{X}_n$.
}

\longnewglossaryentry{atomic outcome}{name=atomic outcome, symbol=\ensuremath{\xi}}
{%
  An outcome that assigns a value to each variable in $\mathcal{X}$.
}

